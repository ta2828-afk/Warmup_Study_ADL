{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Rate Warmup Study - Jupyter Notebook\n",
    "\n",
    "Complete notebook for running the learning rate warmup experiments.\n",
    "\n",
    "**Timeline**: 4 weeks | **GPU Hours**: 20-24 | **Experiments**: 155 (or 124 without MedMNIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install core packages\n",
    "!pip install torch torchvision numpy pandas matplotlib seaborn tqdm scikit-learn pyyaml pillow scipy tensorboard -q\n",
    "\n",
    "# Try to install medmnist (optional)\n",
    "try:\n",
    "    !pip install medmnist --no-deps -q\n",
    "    !pip install fire -q\n",
    "    print(\"✅ MedMNIST installed\")\n",
    "except:\n",
    "    print(\"⚠️  MedMNIST not available - will run 124 experiments instead of 155\")\n",
    "\n",
    "print(\"\\n✅ Installation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Upload Project Files\n",
    "\n",
    "**Option A**: Upload the ZIP file using the file upload button\n",
    "\n",
    "**Option B**: If using Google Colab, run this cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Google Colab: Upload and extract ZIP\n",
    "from google.colab import files\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for filename in uploaded.keys():\n",
    "    with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "        zip_ref.extractall('.')\n",
    "    print(f\"✅ Extracted {filename}\")\n",
    "\n",
    "# Change to project directory\n",
    "os.chdir('warmup_study')\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Verify Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "try:\n",
    "    import medmnist\n",
    "    print(\"✅ MedMNIST available\")\n",
    "except ImportError:\n",
    "    print(\"⚠️  MedMNIST not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Quick Test (5 epochs, ~5 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import ExperimentConfig, DataConfig, ModelConfig, TrainingConfig\n",
    "from train import train\n",
    "\n",
    "# Quick test experiment\n",
    "config = ExperimentConfig(\n",
    "    experiment_name='quick_test',\n",
    "    data=DataConfig(name='cifar10', examples_per_class=100),\n",
    "    model=ModelConfig(num_classes=10),\n",
    "    training=TrainingConfig(\n",
    "        optimizer='sgd',\n",
    "        warmup_epochs=1,\n",
    "        epochs=5,\n",
    "        batch_size=128,\n",
    "        seed=42,\n",
    "        track_interpretability=False\n",
    "    ),\n",
    "    output_dir='./results'\n",
    ")\n",
    "\n",
    "summary = train(config)\n",
    "print(f\"\\n✅ Test complete! Accuracy: {summary['best_val_acc']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Single Full Experiment (~30 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full experiment with 50 epochs\n",
    "config = ExperimentConfig(\n",
    "    experiment_name='cifar10_500epc_w5_sgd',\n",
    "    data=DataConfig(name='cifar10', examples_per_class=500),\n",
    "    model=ModelConfig(num_classes=10),\n",
    "    training=TrainingConfig(\n",
    "        optimizer='sgd',\n",
    "        warmup_epochs=5,\n",
    "        epochs=50,\n",
    "        batch_size=128,\n",
    "        seed=42,\n",
    "        track_interpretability=True\n",
    "    )\n",
    ")\n",
    "\n",
    "summary = train(config)\n",
    "print(f\"\\n✅ Best accuracy: {summary['best_val_acc']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Compare Warmup Durations (~2-3 hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different warmup values\n",
    "results = []\n",
    "\n",
    "for warmup in [0, 1, 5, 10]:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Warmup: {warmup} epochs\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    config = ExperimentConfig(\n",
    "        experiment_name=f'comparison_w{warmup}',\n",
    "        data=DataConfig(name='cifar10', examples_per_class=1000),\n",
    "        model=ModelConfig(num_classes=10),\n",
    "        training=TrainingConfig(\n",
    "            optimizer='sgd',\n",
    "            warmup_epochs=warmup,\n",
    "            epochs=30,\n",
    "            batch_size=128,\n",
    "            seed=42\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    summary = train(config)\n",
    "    results.append({\n",
    "        'warmup': warmup,\n",
    "        'accuracy': summary['best_val_acc'],\n",
    "        'time_min': summary['training_time_seconds'] / 60\n",
    "    })\n",
    "\n",
    "# Display results\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(df_results)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df_results['warmup'], df_results['accuracy'], \n",
    "         marker='o', linewidth=2, markersize=10)\n",
    "plt.xlabel('Warmup Epochs', fontsize=12)\n",
    "plt.ylabel('Best Validation Accuracy (%)', fontsize=12)\n",
    "plt.title('Warmup Effect on Accuracy', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Run All Experiments (20-24 hours)\n",
    "\n",
    "**WARNING**: This will take 20-24 GPU hours. Only run if you have:\n",
    "- Google Colab Pro, or\n",
    "- Kaggle notebook, or\n",
    "- Local GPU\n",
    "\n",
    "For free Colab, run in batches using the week-by-week approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_experiments import run_all_experiments\n",
    "\n",
    "# Run all experiments\n",
    "run_all_experiments(output_dir='./results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative: Run by Week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_experiments import run_week_experiments\n",
    "\n",
    "# Week 1: CIFAR-10 baseline (~4 hours)\n",
    "run_week_experiments(week=1, output_dir='./results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Week 2: CIFAR-10 full (~8 hours)\n",
    "run_week_experiments(week=2, output_dir='./results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Week 3: Cross-dataset (~12 hours)\n",
    "run_week_experiments(week=3, output_dir='./results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Monitor Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import check_progress\n",
    "\n",
    "progress = check_progress('./results')\n",
    "print(f\"Completed: {progress['completed']}/{progress['total']}\")\n",
    "print(f\"Progress: {progress['percentage']:.1f}%\")\n",
    "print(f\"Remaining: {progress['remaining']} experiments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis import WarmupAnalyzer\n",
    "\n",
    "analyzer = WarmupAnalyzer('./results')\n",
    "print(f\"Loaded {len(analyzer.df)} experiments\\n\")\n",
    "\n",
    "# Summary by dataset\n",
    "print(\"=\"*60)\n",
    "print(\"DATASET SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(analyzer.df.groupby('dataset')['best_val_acc'].agg(['count', 'mean', 'std']))\n",
    "\n",
    "# Summary by warmup\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"WARMUP SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(analyzer.df.groupby('warmup_epochs')['best_val_acc'].agg(['count', 'mean', 'std']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Create Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmap for CIFAR-10\n",
    "analyzer.plot_warmup_heatmap('cifar10', 'sgd', metric='best_val_acc')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Find Optimal Warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal = analyzer.find_optimal_warmup('cifar10', 'sgd')\n",
    "print(\"\\nOptimal Warmup Durations:\")\n",
    "print(optimal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Test Hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypotheses = analyzer.test_hypotheses()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"HYPOTHESIS TESTING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for h_name, h_result in hypotheses.items():\n",
    "    print(f\"\\n{h_name}:\")\n",
    "    print(f\"  {h_result['conclusion']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 13: Generate All Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate_visualizations import generate_all_visualizations\n",
    "\n",
    "generate_all_visualizations(\n",
    "    results_dir='./results',\n",
    "    output_dir='./visualizations'\n",
    ")\n",
    "\n",
    "print(\"✅ All visualizations created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 14: Display Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import os\n",
    "\n",
    "# Display key plots\n",
    "viz_files = [\n",
    "    './visualizations/comparisons/warmup_comparison_across_datasets.png',\n",
    "    './visualizations/comparisons/sgd_vs_adamw_comparison.png',\n",
    "    './visualizations/comparisons/optimal_warmup_vs_dataset_size.png'\n",
    "]\n",
    "\n",
    "for viz_file in viz_files:\n",
    "    if os.path.exists(viz_file):\n",
    "        print(f\"\\n{os.path.basename(viz_file)}:\")\n",
    "        display(Image(filename=viz_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 15: Download Results (Google Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package and download results\n",
    "import shutil\n",
    "from google.colab import files\n",
    "\n",
    "# Create ZIPs\n",
    "shutil.make_archive('warmup_results', 'zip', './results')\n",
    "shutil.make_archive('warmup_visualizations', 'zip', './visualizations')\n",
    "\n",
    "# Download\n",
    "files.download('warmup_results.zip')\n",
    "files.download('warmup_visualizations.zip')\n",
    "\n",
    "print(\"✅ Downloads started!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Save to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Copy results to Drive\n",
    "!cp -r ./results /content/drive/MyDrive/warmup_study_results\n",
    "!cp -r ./visualizations /content/drive/MyDrive/warmup_study_visualizations\n",
    "\n",
    "print(\"✅ Results saved to Google Drive!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
